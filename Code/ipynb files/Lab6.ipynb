{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d1c066-1a7b-4ba5-a3db-4e4df663ec44",
   "metadata": {},
   "source": [
    "<h1> Lab 6 </h1> \n",
    "<h3> Akshita Gundavarau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9845604-39de-4b26-af4e-5f9a4aaa07cd",
   "metadata": {},
   "source": [
    "<h2> 1 Confusion Matrix </h2>\n",
    "<h3> 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9d38-8817-4ce0-a5a0-30c8f011d138",
   "metadata": {},
   "source": [
    "\n",
    "<h5> M1: </h5>\n",
    "\n",
    "| | **Predicted** | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | Poisonous | Edible |\n",
    "|**Actual**| 3 | 0 |\n",
    "||3|4|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692793c-863b-4d2d-882a-9b9eb7843fca",
   "metadata": {},
   "source": [
    "<h5> M2: </h5>\n",
    "\n",
    "| | **Predicted** | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | Poisonous | Edible |\n",
    "|**Actual**| 2 | 1 |\n",
    "||0|7|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bf007-0956-4f2d-a96e-27d006289348",
   "metadata": {},
   "source": [
    "<h3> 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d7753-f80e-4fb4-bd8b-795bb5c5acaf",
   "metadata": {},
   "source": [
    "Accuracy = (True poisonous + True edible) / Total \n",
    "\n",
    "Precision = (True Edible / Total Predicted Edible)\n",
    "\n",
    "Recall = (True Edible / Total Actual Edible)\n",
    "\n",
    "<h4> M1: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa1ec956-ebc1-4b12-bd93-e2648afe43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_accuracy = (4+3)/10\n",
    "M1_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ca1fe39-51a8-4c59-9524-5ac2ac51a487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_precision = 4/4\n",
    "M1_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cead03ce-0c02-4eff-8605-155c7a154ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1_recall = 4/7\n",
    "M1_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d881d9-9dcd-40b3-bd3f-51d8c25a9106",
   "metadata": {},
   "source": [
    "<h4> M2: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204cd426-a593-48ef-be6e-145c21551d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_accuracy = (7+2)/10\n",
    "M2_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecd29600-4ccc-4bda-b6f3-fe1daa7078c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_precision = 7/8\n",
    "M2_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5cd0103-3b77-42e6-b1db-68fca8c58a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_recall = 7/7\n",
    "M2_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31220e-f8fd-4b65-80ef-d8c9c573198e",
   "metadata": {},
   "source": [
    "<h3> 1.3 </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d899e71-62bf-49a0-a26c-7e9a3cc1f87b",
   "metadata": {},
   "source": [
    "Which model, M1 or M2 will you recommend him to use? Explain your reasoning!\n",
    "\n",
    "For this question. Having a false positive is bad. This would mean that the model predicts that the mushroom is edible but it is actually poisonous. Precision measures the percentage of predicted positives that are captured. \n",
    "\n",
    "M1 had a precision of 100% while M2 has a precision of 87.5%. \n",
    "\n",
    "Therefore, I would suggest to use Model 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b28ce-173f-47e4-98aa-aaf63f45d5f2",
   "metadata": {},
   "source": [
    "<h3> 1.4 </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df336b-db74-4722-b0dc-dc9586d23792",
   "metadata": {},
   "source": [
    "<h5> M3: </h5>\n",
    "\n",
    "| | **Predicted** | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | Innocent | Guilty |\n",
    "|**Actual**| 3 | 2 |\n",
    "||1|4|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe43561-ae0e-4613-a2ba-5ab4228706e8",
   "metadata": {},
   "source": [
    "<h5> M4: </h5>\n",
    "\n",
    "| | **Predicted** | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | Innocent | Guilty |\n",
    "|**Actual**| 5 | 0 |\n",
    "||3|2|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b7d98-d2eb-438e-bb65-7b89816fa27a",
   "metadata": {},
   "source": [
    "<h3> 1.5 </h3>\n",
    "\n",
    "Accuracy = (True Guilty + True Innocent) / Total \n",
    "\n",
    "Precision = (True Guilty / Total Predicted Guilty)\n",
    "\n",
    "Recall = (True Guilty / Total Actual Guilty)\n",
    "\n",
    "<h4> M3: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9507d061-5415-43d2-af24-c1eaaf8ab128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3_accuracy = (4+3)/10\n",
    "M3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0398b586-fb6a-4f51-9ef8-76764cee4a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3_precision = 4/6\n",
    "M3_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df60534b-6b54-44d6-bc9c-8edd371c66b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M3_recall = 4/5\n",
    "M3_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49acd1d3-60fe-4df2-9b82-d0f084fd3d8d",
   "metadata": {},
   "source": [
    "<h4> M4: </h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "845aa1e6-9128-489b-b786-58e60f708042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M4_accuracy = (2+5)/10\n",
    "M4_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d945f72-be1f-4d53-a7da-3750f522e088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M4_precision = 2/2\n",
    "M4_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90442b21-e5ae-4346-9dab-1ed8fe6de2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2_recall = 2/5\n",
    "M2_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae465573-08d4-4e17-93e6-52a2364d7c01",
   "metadata": {},
   "source": [
    "<h3> 1.6 </h3> \n",
    "\n",
    "Which model would you recommend her to use? Explain your reasoning!\n",
    "\n",
    "For this question. Having a false positive is bad. This would mean that the model predicts that the someone is guilty but they are actually innocent. Precision measures the percentage of predicted positives that are captured. \n",
    "\n",
    "M4 had a precision of 100% while M3 has a precision of 66.6%. \n",
    "\n",
    "Therefore, I would suggest to use Model 4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fd6df-f861-459f-a5a7-92cb4f267cb9",
   "metadata": {},
   "source": [
    "<h3> 1.7 </h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9186a0-50f2-4cac-8439-47b4956c16e1",
   "metadata": {},
   "source": [
    "<h5> M5: </h5>\n",
    "\n",
    "| | **Predicted** | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | Others | Simolestes Vorax  |\n",
    "|**Actual**| 3 | 2 |\n",
    "||1|4|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6216e-3e5a-47e3-83b6-465b1201c3a7",
   "metadata": {},
   "source": [
    "<h5> M6: </h5>\n",
    "\n",
    "| | **Predicted** | |\n",
    "| -------- | ------------: | ------:|\n",
    "| | Others | Simolestes Vorax  |\n",
    "|**Actual**| 2| 3 |\n",
    "||0|5|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bac86-656c-44c2-97c2-116df98a83f9",
   "metadata": {},
   "source": [
    "<h3> 1.8 </h3>\n",
    "\n",
    "Accuracy = (True Simolestes Vorax  + True Others) / Total \n",
    "\n",
    "Precision = (True Simolestes Vorax / Total Predicted Simolestes Vorax)\n",
    "\n",
    "Recall = (True Simolestes Vorax / Total Actual Simolestes Vorax)\n",
    "\n",
    "F-score = 2 / ( (1 / precision) + (1 / recall) )\n",
    "\n",
    "<h4> M5: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db4c1173-5aad-4643-8e45-0a07a471c401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5_accuracy = (3+4)/10\n",
    "M5_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c08827c-7abe-422e-a8d5-3556ff84e1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5_precision = 4/6\n",
    "M5_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c093e001-cf95-4249-bbdf-1cc3fa737ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5_recall = 4/5\n",
    "M5_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4935bb39-dbb4-4871-a135-5ed3138ef43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M5_f_score = 2 / ((1/M5_precision) + (1/M5_recall))\n",
    "M5_f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93d710-f902-4687-9337-b18f74e781d5",
   "metadata": {},
   "source": [
    "<h4> M6: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a60585f-3e5b-4fb6-9ac0-b832080ea1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6_accuracy = (2+5)/10\n",
    "M6_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e93cf5fb-61be-447a-8d0d-b347fc16f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6_precision = 5/8\n",
    "M6_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcc7e01b-26f5-4d74-9cf8-6dccf7fd557d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6_recall = 5/5\n",
    "M6_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a24a97bb-0337-4c2b-a5b6-e3bcfb9fc17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692307692307692"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M6_f_score = 2 / ((1/M6_precision) + (1/M6_recall))\n",
    "M6_f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55964d1c-86fe-465b-b0b9-04178e03cd82",
   "metadata": {},
   "source": [
    "<h3> 1.8 </h3> \n",
    "\n",
    "Which of these two models, M5 or M6 will you recommend him? Explain to him."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba246f-b0da-4f22-aef6-dc4083de0e70",
   "metadata": {},
   "source": [
    "For this question it is hard to determine if having a false positive is worse than having a false negative. Hence we will use the F-score values (harmonic mean of Precision, Recall) to figure out which model is better. Overall, it is better to have a higher precision and higher recall. The F-score will  \n",
    "\n",
    "The F-score of M5 is 72.7%. The F-score of MS is "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
